{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from kiwipiepy import Kiwi\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis.gensim_models\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/뉴스_크롤링.xlsx'\n",
    "df = pd.read_excel(data_path, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용할 토크나이저 생성\n",
    "- 한국어 형태소분석기인 kiwi 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer:\n",
    "    def __init__(self, kiwi):\n",
    "        self.kiwi = kiwi\n",
    "    def __call__(self, text):\n",
    "        result = list()\n",
    "        for token in self.kiwi.tokenize(text):\n",
    "            if token[1] in [\"NNG\", \"NNP\", \"NNB\", \"NR\", \"NP\"] and int(token[3]) > 1:\n",
    "                result.append(token[0])\n",
    "        return result\n",
    "    \n",
    "mytokenizer = MyTokenizer(Kiwi())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "명사 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content2nouns'] = df['Content'].apply(lambda x: mytokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딕셔너리 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content2nouns'] = df['content2nouns'].apply(lambda x: ', '.join(x).replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = list(df['content2nouns'].apply(lambda x: x.split( )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA와 내부에서 받는 자료형태로 변환\n",
    "dictionary = corpora.Dictionary(text_data)\n",
    "\n",
    "# doc2bow를 이용해 코퍼스 생성\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## toic perplexity 확인\n",
    "- 혼란도\n",
    "- 모델이 얼마나 정확하게 예측하는지를 확인함\n",
    "- 낮을수록 정확하게 예측함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(dictionary, corpus, start, limit, step):\n",
    "    perplexity_values = []\n",
    "\n",
    "    for i in range(start, limit, step):\n",
    "        model = LdaModel(corpus=corpus, num_topics=i, id2word=dictionary, random_state=42)\n",
    "        perplexity_values.append(model.log_perplexity(corpus))\n",
    "    \n",
    "    return perplexity_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작할 최소 토픽 개수\n",
    "start=1\n",
    "# 최대 한계\n",
    "limit=15\n",
    "# 단계별 증가시킬 토픽 수\n",
    "step=1\n",
    "\n",
    "perplexity_values = compute_perplexity(dictionary=dictionary, corpus=corpus, start=start, limit=limit, step=step)\n",
    "\n",
    "# 토픽의 개수별 perplexity 확인\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, perplexity_values)\n",
    "plt.xlabel(\"Number Of Topics\")\n",
    "plt.ylabel(\"Perplexity score\")\n",
    "plt.show()\n",
    "\n",
    "# perplexity scores 출력\n",
    "i=0\n",
    "for n, pv in enumerate(perplexity_values):\n",
    "    print(f\"Number Of Topics =\", n, \" has perplexity Value of\", round(pv, 4))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## topic coherence score 확인\n",
    "- 토픽이 얼마나 일관성 있는지를 판단\n",
    "- 높을수록 의미론적 일관성이 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, start, limit, step):\n",
    "    coherence_values = []\n",
    "    \n",
    "    for i in range(start, limit, step):\n",
    "        # model = LdaModel(corpus=corpus, num_topics=i, id2word=dictionary, random_state=42, update_every=1, chunksize=100, passes=10, alpha='auto', per_word_topics=True)\n",
    "        model = LdaModel(corpus=corpus, num_topics=i, id2word=dictionary, random_state=42)\n",
    "        coherence_model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_lda = coherence_model.get_coherence()\n",
    "        coherence_values.append(coherence_lda)\n",
    "\n",
    "    return coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작할 최소 토픽 개수\n",
    "start=1\n",
    "# 최대 한계\n",
    "limit=15\n",
    "# 단계별 증가시킬 토픽 수\n",
    "step=1\n",
    "\n",
    "coherence_values = compute_coherence_values(dictionary=dictionary, corpus=corpus, texts=text_data, start=start, limit=limit, step=step)\n",
    "\n",
    "# 토픽의 개수별 Coherence Score 스코어 확인\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Number Of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.show()\n",
    "\n",
    "# coherence scores 출력\n",
    "i=0\n",
    "for m, cv in enumerate(coherence_values):\n",
    "    print(\"Number Of Topics =\", m, \" has Coherence Value of\", round(cv, 4))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lda config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 14\n",
    "topic_word_num = 10\n",
    "seed = 42\n",
    "update_every = 1\n",
    "chunksize = 100\n",
    "passes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 정의\n",
    "lda_model = LdaModel(corpus=corpus, \n",
    "                     id2word=dictionary,\n",
    "                     num_topics=num_topics,\n",
    "                     random_state=seed,\n",
    "                     )\n",
    "\n",
    "# 토픽 출력\n",
    "print(lda_model.print_topics(num_words=topic_word_num))\n",
    "\n",
    "# 모델 저장 \n",
    "lda_model.save('./lda_results/news_lda_topic_modeling.lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word = []\n",
    "for topic_id in range(num_topics):\n",
    "    topic_word_probs = lda_model.show_topic(topic_id, topic_word_num)\n",
    "    for topic_word in topic_word_probs:\n",
    "        list_word.append(topic_word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word_set = list(set(list_word))\n",
    "series_word = pd.Series(list_word_set, name = 'keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_word.to_excel('./lda_results/news_data_topic_word.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_visualization = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary, sort_topics=False, n_jobs=1)\n",
    "pyLDAvis.save_html(lda_visualization, 'lda_result_vis.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertopic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
