{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from kiwipiepy import Kiwi\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis.gensim_models\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/뉴스_크롤링.xlsx'\n",
    "df = pd.read_excel(data_path, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용할 토크나이저 생성\n",
    "- 한국어 형태소분석기인 kiwi 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer:\n",
    "    def __init__(self, kiwi):\n",
    "        self.kiwi = kiwi\n",
    "    def __call__(self, text):\n",
    "        result = list()\n",
    "        for token in self.kiwi.tokenize(text):\n",
    "            if token[1] in [\"NNG\", \"NNP\", \"NNB\", \"NR\", \"NP\"] and int(token[3]) > 1:\n",
    "                result.append(token[0])\n",
    "        return result\n",
    "    \n",
    "mytokenizer = MyTokenizer(Kiwi())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "명사 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content2nouns'] = df['Content'].apply(lambda x: mytokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딕셔너리 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content2nouns'] = df['content2nouns'].apply(lambda x: ', '.join(x).replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = list(df['content2nouns'].apply(lambda x: x.split( )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토픽 모델링 딕셔너리 생성\n",
    "id2word = corpora.Dictionary(text_data)\n",
    "\n",
    "# 토픽모델링에 사용할 말뭉치 생성\n",
    "texts = text_data\n",
    "\n",
    "# 용어-문서 빈도\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## topic coherence score 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start, step):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaModel(corpus=corpus,id2word=id2word,num_topics=num_topics,random_state=100,update_every=1,chunksize=100,passes=10,alpha='auto',per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=text_data, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작할 최소 토픽 개수\n",
    "start=1\n",
    "# 최대 한계\n",
    "limit=15\n",
    "# 단계별 증가시킬 토픽 수\n",
    "step=1\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=text_data, start=start, limit=limit, step=step)\n",
    "\n",
    "# 토픽의 개수별 Coherence Score 스코어 확인\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n",
    "# coherence scores 출력\n",
    "i=0\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4), \"model_number : {}\".format(i))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average topic coherence = 전체 topic의 topic coherences를 더한 값을 topic 수로 나눈 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model_list:\n",
    "    top_topics = m.top_topics(corpus)\n",
    "    avg_topic_coherence = sum([t[1] for t in top_topics]) / 15\n",
    "    print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "    print(top_topics)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lda config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 12\n",
    "topic_word_num = 10\n",
    "seed = 42\n",
    "update_every = 1\n",
    "chunksize = 100\n",
    "passes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 정의\n",
    "lda_model = LdaModel(corpus=corpus, \n",
    "                     id2word=id2word,\n",
    "                     num_topics=num_topics,\n",
    "                     random_state=seed,\n",
    "                     update_every=update_every,\n",
    "                     chunksize=chunksize,\n",
    "                     passes=passes,\n",
    "                     alpha='auto',\n",
    "                     per_word_topics=True)\n",
    "\n",
    "# 토픽 출력\n",
    "print(lda_model.print_topics(num_words=topic_word_num))\n",
    "doc_lda = lda_model[corpus]\n",
    "\n",
    "# 모델 저장 \n",
    "lda_model.save('./lda_results/news_lda_topic_modeling.lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word = []\n",
    "for topic_id in range(num_topics):\n",
    "    topic_word_probs = lda_model.show_topic(topic_id, topic_word_num)\n",
    "    for topic_word in topic_word_probs:\n",
    "        list_word.append(topic_word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word_set = list(set(list_word))\n",
    "series_word = pd.Series(list_word_set, name = 'keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_word.to_excel('./lda_results/news_data_topic_word.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_visualization = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, sort_topics=False, n_jobs=1)\n",
    "pyLDAvis.save_html(lda_visualization, 'lda_result_vis.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertopic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
